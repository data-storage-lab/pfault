(1) Feb07 19:51:09 Main [App] >> Version: 7.2
(2) Feb07 19:51:09 Main [App] >> LocalNode: beegfs-mgmtd mgs [ID: 1]
(2) Feb07 19:51:09 Main [App] >> Usable NICs: virbr0(TCP) enp0s3(TCP) 
(2) Feb07 19:51:15 DirectWorker1 [Change consistency states] >> Metadata node is coming online. ID: 2
(2) Feb07 19:51:17 Worker1 [Change consistency states] >> Storage target is coming online. ID: 501
(2) Feb07 19:51:18 Worker2 [Change consistency states] >> Storage target is coming online. ID: 301
(2) Feb07 19:51:19 XNodeSync [Assign node to capacity pool] >> Metadata node capacity pool assignment updated. NodeID: 2; Pool: Normal; Reason: Free capacity threshold
(2) Feb07 19:51:19 XNodeSync [Assign target to capacity pool] >> Storage target capacity pool assignment updated. NodeID: 4; TargetID: 401; Pool: Emergency;  Reason: No capacity report received.
(2) Feb07 19:51:21 Worker2 [Change consistency states] >> Storage target is coming online. ID: 401
(2) Feb07 19:51:22 Worker2 [RemoveNodeMsgEx.cpp:66] >> Node removed. node: beegfs-client 240B-60208A7A-osboxes [ID: 5]
(2) Feb07 19:51:24 XNodeSync [Assign target to capacity pool] >> Storage target capacity pool assignment updated. NodeID: 4; TargetID: 401; Pool: Low;  Reason: Free capacity threshold
(2) Feb07 19:51:26 Worker2 [Node registration] >> New node: beegfs-client 2BA7-60208B0E-osboxes [ID: 6]; Source: 10.0.0.121:56008
(2) Feb07 19:53:29 XNodeSync [Auto-offline] >> No state report received from metadata node for 92 seconds. Setting metadata node to probably-offline. Metadata node ID: 2
(2) Feb07 19:54:29 XNodeSync [Assign node to capacity pool] >> Metadata node capacity pool assignment updated. NodeID: 2; Pool: Emergency; Reason: No capacity report received.
(2) Feb07 19:54:59 XNodeSync [Auto-offline] >> No state report received from metadata node for 182 seconds. Setting metadata node to offline. Metadata node ID: 2
